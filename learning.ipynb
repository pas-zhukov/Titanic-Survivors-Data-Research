{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Настройка обучения"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from networks import Net\n",
    "from data_functions import TitanicDataset, get_loaders\n",
    "from metrics_functions import compute_binary_accuracy, validation_loss\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = 'cuda:0'\n",
    "else:\n",
    "    dev = 'cpu'\n",
    "device = torch.device(dev)\n",
    "\n",
    "model = Net()\n",
    "model.to(device)\n",
    "model.type(torch.cuda.FloatTensor)\n",
    "\n",
    "# Hyper Params\n",
    "num_epochs = 3000\n",
    "batch_size = 32\n",
    "learning_rate = 1e-2\n",
    "weight_decay = 1e-2\n",
    "validation_split = .1\n",
    "\n",
    "# Загрузка данных\n",
    "data_train = TitanicDataset(normalize=True)\n",
    "train_loader, val_loader = get_loaders(batch_size=batch_size, data_train=data_train, validation_split=validation_split)\n",
    "\n",
    "# Loss Function, Optimizer\n",
    "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# LR Annealing\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=.6, patience=100)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Обучение"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4168848/3515371177.py:8: NeptuneWarning: To avoid unintended consumption of logging hours during interactive sessions, the following monitoring options are disabled unless set to 'True' when initializing the run: 'capture_stdout', 'capture_stderr', and 'capture_hardware_metrics'.\n",
      "  run = neptune.init_run(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://new-ui.neptune.ai/pas-zhukov/Titanic-Kaggle/e/TIT-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3000 [00:00<?, ?it/s]/home/pavel/PycharmProjects/titanic-kaggle/networks.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n",
      "/tmp/ipykernel_4168848/3515371177.py:44: NeptuneUnsupportedType: You're attempting to log a type that is not directly supported by Neptune (<class 'list'>).\n",
      "        Convert the value to a supported type, such as a string or float, or use stringify_unsupported(obj)\n",
      "        for dictionaries or collections that contain unsupported values.\n",
      "        For more, see https://docs.neptune.ai/help/value_of_unsupported_type\n",
      "  run['train/batch/loss'].append(loss)\n",
      " 66%|██████▋   | 1995/3000 [12:59<06:32,  2.56it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.92 GiB total capacity; 2.11 GiB already allocated; 44.44 MiB free; 2.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOutOfMemoryError\u001B[0m                          Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 48\u001B[0m\n\u001B[1;32m     46\u001B[0m loss_value\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;66;03m# Обновляем веса\u001B[39;00m\n\u001B[0;32m---> 48\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;66;03m# Определяем индексы, соответствующие выбранным моделью лейблам\u001B[39;00m\n\u001B[1;32m     51\u001B[0m _, indices \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmax(prediction, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    276\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    277\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    278\u001B[0m                                \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbut got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 280\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    283\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     32\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m---> 33\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     35\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(prev_grad)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:141\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    130\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m    132\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    133\u001B[0m         group,\n\u001B[1;32m    134\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    138\u001B[0m         max_exp_avg_sqs,\n\u001B[1;32m    139\u001B[0m         state_steps)\n\u001B[0;32m--> 141\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    145\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    146\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    148\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:281\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    279\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 281\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m     \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m     \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[43m     \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    288\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[43m     \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[43m     \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    291\u001B[0m \u001B[43m     \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    292\u001B[0m \u001B[43m     \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    293\u001B[0m \u001B[43m     \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    294\u001B[0m \u001B[43m     \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    295\u001B[0m \u001B[43m     \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    296\u001B[0m \u001B[43m     \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[43m     \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/torch/optim/adam.py:442\u001B[0m, in \u001B[0;36m_multi_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    439\u001B[0m torch\u001B[38;5;241m.\u001B[39m_foreach_add_(device_state_steps, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    441\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weight_decay \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 442\u001B[0m     device_grads \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_foreach_add\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice_grads\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malpha\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    444\u001B[0m \u001B[38;5;66;03m# Decay the first and second moment running average coefficient\u001B[39;00m\n\u001B[1;32m    445\u001B[0m torch\u001B[38;5;241m.\u001B[39m_foreach_mul_(device_exp_avgs, beta1)\n",
      "\u001B[0;31mOutOfMemoryError\u001B[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 7.92 GiB total capacity; 2.11 GiB already allocated; 44.44 MiB free; 2.16 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import neptune\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"pas-zhukov/Titanic-Kaggle\",\n",
    "    api_token=config['Config']['api_token'],\n",
    "    source_files=['networks.py', 'learning.ipynb', 'metrics_functions.py', 'data_functions.py']\n",
    ")\n",
    "params = {\n",
    "    'num_epochs': num_epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'learning_rate': learning_rate,\n",
    "    'weight_decay': weight_decay,\n",
    "    'validation_split': validation_split,\n",
    "    'optimizer': 'Adam',\n",
    "    'annealing_factor': .8\n",
    "}\n",
    "run[\"parameters\"] = params\n",
    "\n",
    "loss_history = []\n",
    "val_loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "lr_history = []\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "\n",
    "    loss_accum = 0\n",
    "    correct_samples = 0\n",
    "    total_samples = 0\n",
    "    for i_step, (x, y) in enumerate(train_loader):\n",
    "\n",
    "        run['train/batch/lr'].append(scheduler.optimizer.param_groups[0]['lr'])\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        prediction = model(x)\n",
    "        loss_value = loss(prediction, y)\n",
    "        run['train/batch/loss'].append(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        # Обновляем веса\n",
    "        optimizer.step()\n",
    "\n",
    "        # Определяем индексы, соответствующие выбранным моделью лейблам\n",
    "        _, indices = torch.max(prediction, dim=1)\n",
    "        # Сравниваем с ground truth, сохраняем количество правильных ответов\n",
    "        correct_samples += torch.sum(indices == y)\n",
    "        # Сохраняем количество всех предсказаний\n",
    "        total_samples += y.shape[0]\n",
    "        run['train/batch/acc'].append(correct_samples/total_samples)\n",
    "\n",
    "        loss_accum += loss_value\n",
    "\n",
    "    # Среднее значение функции потерь за эпоху\n",
    "    ave_loss = loss_accum / (i_step + 1)\n",
    "    # Рассчитываем точность тренировочных данных на эпохе\n",
    "    train_accuracy = float(correct_samples) / total_samples\n",
    "    # Рассчитываем точность на валидационной выборке (вообще после этого надо бы гиперпараметры поподбирать...)\n",
    "    val_accuracy = compute_binary_accuracy(model, val_loader)\n",
    "\n",
    "    # Сохраняем значения ф-ии потерь и точности для последующего анализа и построения графиков\n",
    "    loss_history.append(float(ave_loss))\n",
    "    train_history.append(train_accuracy)\n",
    "    val_history.append(val_accuracy)\n",
    "\n",
    "    #Посчитаем лосс на валидационной выборке\n",
    "    val_loss = validation_loss(model, val_loader, loss)\n",
    "    val_loss_history.append(val_loss)\n",
    "\n",
    "    run['train/epoch/loss'].append(ave_loss)\n",
    "    run['valid/epoch/loss'].append(val_loss)\n",
    "    run['train/epoch/acc'].append(train_accuracy)\n",
    "    run['valid/epoch/acc'].append(val_accuracy)\n",
    "    run['train/epoch/lr'].append(scheduler.optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    lr_history.append(scheduler.optimizer.param_groups[0]['lr'])\n",
    "    # Уменьшаем лернинг рейт (annealing)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Генерация предсказаний для тестовой выборки"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pavel/PycharmProjects/titanic-kaggle/networks.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": "     PassengerId  Survived\n0            892         0\n1            893         0\n2            894         0\n3            895         0\n4            896         1\n..           ...       ...\n413         1305         0\n414         1306         1\n415         1307         0\n416         1308         0\n417         1309         1\n\n[418 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>892</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>893</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>894</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>895</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>896</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>413</th>\n      <td>1305</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>414</th>\n      <td>1306</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>415</th>\n      <td>1307</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>416</th>\n      <td>1308</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>417</th>\n      <td>1309</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>418 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_set = TitanicDataset(test=True, normalize=True)\n",
    "test_loader = DataLoader(test_set, batch_size=1)\n",
    "\n",
    "predictions = []\n",
    "labels = {}\n",
    "\n",
    "for i_step, (x, y) in enumerate(test_loader):\n",
    "    x = x.to(device)\n",
    "    model.eval()\n",
    "    prediction = model(x)\n",
    "    predictions.append(torch.argmax(prediction, dim=1))\n",
    "    labels[i_step+892] = int(torch.argmax(prediction, dim=1))\n",
    "\n",
    "\n",
    "output = pd.DataFrame(labels.items(), columns = ['PassengerId', 'Survived'])\n",
    "output.to_csv(os.path.join('outputs/output'+datetime.datetime.now().strftime('%d%m%y%H%M')+'.csv'), index=False)\n",
    "output"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
